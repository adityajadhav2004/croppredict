{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Mb4L8vtJatgoRWwOviurWtkahUXWP6fF",
      "authorship_tag": "ABX9TyN9G2RhoYZnI3aS/uHloL/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityajadhav2004/croppredict/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9UvA__A-XAL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWnH5bGX-8_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive/cropdatasets/crop_yield_fertilizer_300.csv')"
      ],
      "metadata": {
        "id": "MKEe4qUz_Wxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z595qQ5m_7uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1127e7dd"
      },
      "source": [
        "# Task\n",
        "Analyze and predict crop yield using the 'crop_yield_fertilizer_300.csv' dataset from Google Drive, employing an XGBoost Regressor model. The task involves data loading, preprocessing, hyperparameter tuning to achieve an R² score between 0.90 and 0.97, visualizing feature importance, and summarizing the findings regarding N–P–K components and climate factors' influence on crop yield."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65353804"
      },
      "source": [
        "## Mount Google Drive and Load Data\n",
        "\n",
        "### Subtask:\n",
        "Mount your Google Drive to access the dataset and then load the 'crop_yield_fertilizer_300.csv' file into a pandas DataFrame. This step will also handle basic data inspection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "345dea89"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires mounting Google Drive, loading the specified CSV file into a pandas DataFrame, and then performing initial data inspection steps. The existing mount command in the notebook is incorrect, so I will provide a corrected one along with the data loading and inspection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57433a93",
        "outputId": "a6a00373-c37c-4b98-af8b-7f2350b9f32a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/drive/MyDrive/cropdatasets/crop_yield_fertilizer_300.csv'\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"\\nDataFrame loaded successfully. Displaying the first 5 rows:\")\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDisplaying concise summary of the DataFrame:\")\n",
        "# Get a concise summary of the DataFrame\n",
        "df.info()\n",
        "\n",
        "print(\"\\nGenerating descriptive statistics of the DataFrame:\")\n",
        "# Generate descriptive statistics of the DataFrame\n",
        "print(df.describe())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "\n",
            "DataFrame loaded successfully. Displaying the first 5 rows:\n",
            "   ID       Crop  Temperature (°C)  Rainfall (mm)  Soil pH  Nitrogen (N)  \\\n",
            "0   1      Maize              26.2           1218      5.9            59   \n",
            "1   2       Rice              27.6           1338      5.5            63   \n",
            "2   3      Wheat              24.5            599      6.0            62   \n",
            "3   4  Sugarcane              34.6           1274      6.5            33   \n",
            "4   5     Cotton              18.8           1196      6.0            43   \n",
            "\n",
            "   Phosphorus (P)  Potassium (K)  Yield (tons/ha)  \n",
            "0              67             34             6.27  \n",
            "1              56             16             6.30  \n",
            "2              50             55             2.78  \n",
            "3              68             17             1.94  \n",
            "4              33             32             4.46  \n",
            "\n",
            "Displaying concise summary of the DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300 entries, 0 to 299\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ID                300 non-null    int64  \n",
            " 1   Crop              300 non-null    object \n",
            " 2   Temperature (°C)  300 non-null    float64\n",
            " 3   Rainfall (mm)     300 non-null    int64  \n",
            " 4   Soil pH           300 non-null    float64\n",
            " 5   Nitrogen (N)      300 non-null    int64  \n",
            " 6   Phosphorus (P)    300 non-null    int64  \n",
            " 7   Potassium (K)     300 non-null    int64  \n",
            " 8   Yield (tons/ha)   300 non-null    float64\n",
            "dtypes: float64(3), int64(5), object(1)\n",
            "memory usage: 21.2+ KB\n",
            "\n",
            "Generating descriptive statistics of the DataFrame:\n",
            "               ID  Temperature (°C)  Rainfall (mm)     Soil pH  Nitrogen (N)  \\\n",
            "count  300.000000        300.000000     300.000000  300.000000    300.000000   \n",
            "mean   150.500000         24.714000    1179.640000    6.454000     53.863333   \n",
            "std     86.746758          5.797572     455.797515    0.569061     14.558083   \n",
            "min      1.000000         15.100000     407.000000    5.500000     30.000000   \n",
            "25%     75.750000         19.775000     791.000000    6.000000     40.750000   \n",
            "50%    150.500000         24.300000    1204.500000    6.400000     54.000000   \n",
            "75%    225.250000         29.900000    1565.750000    6.900000     65.000000   \n",
            "max    300.000000         35.000000    1998.000000    7.500000     80.000000   \n",
            "\n",
            "       Phosphorus (P)  Potassium (K)  Yield (tons/ha)  \n",
            "count      300.000000     300.000000       300.000000  \n",
            "mean        45.436667      38.610000         4.111633  \n",
            "std         14.438869      13.694636         1.649367  \n",
            "min         20.000000      15.000000         1.520000  \n",
            "25%         33.000000      26.000000         2.607500  \n",
            "50%         46.000000      39.000000         4.090000  \n",
            "75%         57.000000      51.000000         5.445000  \n",
            "max         70.000000      60.000000         7.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5fa560"
      },
      "source": [
        "## Preprocess Data\n",
        "\n",
        "### Subtask:\n",
        "Perform necessary data preprocessing steps, similar to what would be done for a Random Forest model. This includes handling missing values, encoding categorical features if any, and splitting the data into features (X) and target (y) for model training and testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94d2f6af"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll separate the target variable, drop the 'ID' column, and apply one-hot encoding to the 'Crop' column, storing the features in `X` and the target in `y`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eece89d0",
        "outputId": "c46d8814-e0b0-4ed3-8112-b0ba7bbc9407"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Separate the target variable, 'Yield (tons/ha)', from the features.\n",
        "y = df['Yield (tons/ha)']\n",
        "X = df.drop('Yield (tons/ha)', axis=1)\n",
        "\n",
        "# 2. Drop the 'ID' column\n",
        "X = X.drop('ID', axis=1)\n",
        "\n",
        "# 3. Apply one-hot encoding to the 'Crop' column\n",
        "X = pd.get_dummies(X, columns=['Crop'], drop_first=True)\n",
        "\n",
        "print(\"Features (X) after preprocessing:\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget (y) after preprocessing:\")\n",
        "print(y.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) after preprocessing:\n",
            "   Temperature (°C)  Rainfall (mm)  Soil pH  Nitrogen (N)  Phosphorus (P)  \\\n",
            "0              26.2           1218      5.9            59              67   \n",
            "1              27.6           1338      5.5            63              56   \n",
            "2              24.5            599      6.0            62              50   \n",
            "3              34.6           1274      6.5            33              68   \n",
            "4              18.8           1196      6.0            43              33   \n",
            "\n",
            "   Potassium (K)  Crop_Cotton  Crop_Maize  Crop_Millet  Crop_Rice  \\\n",
            "0             34        False        True        False      False   \n",
            "1             16        False       False        False       True   \n",
            "2             55        False       False        False      False   \n",
            "3             17        False       False        False      False   \n",
            "4             32         True       False        False      False   \n",
            "\n",
            "   Crop_Soybean  Crop_Sugarcane  Crop_Wheat  \n",
            "0         False           False       False  \n",
            "1         False           False       False  \n",
            "2         False           False        True  \n",
            "3         False            True       False  \n",
            "4         False           False       False  \n",
            "\n",
            "Target (y) after preprocessing:\n",
            "0    6.27\n",
            "1    6.30\n",
            "2    2.78\n",
            "3    1.94\n",
            "4    4.46\n",
            "Name: Yield (tons/ha), dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3caeab0"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to split the preprocessed data into training and testing sets using `train_test_split` from `sklearn.model_selection`, with a `test_size` of 0.2 and a `random_state` for reproducibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d1b4683",
        "outputId": "68fc9a67-8553-40a0-de70-26781fd99e93"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (240, 13)\n",
            "X_test shape: (60, 13)\n",
            "y_train shape: (240,)\n",
            "y_test shape: (60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48d96045"
      },
      "source": [
        "## Train and Tune XGBoost Model\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train an XGBoost Regressor model. Implement hyperparameter tuning for key parameters such as 'learning_rate', 'n_estimators', and 'max_depth' to optimize model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4426702e"
      },
      "source": [
        "**Reasoning**:\n",
        "I will import the necessary libraries, instantiate the XGBoost Regressor, define the hyperparameter grid, initialize and fit `GridSearchCV` to the training data, and then print the best parameters and store the best model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "120c5b36",
        "outputId": "b52e63a0-5056-4ac9-ef70-8233656ecd13"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 2. Instantiate an XGBRegressor model\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "\n",
        "# 3. Define a parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# 4. Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid,\n",
        "                           scoring='r2', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# 5. Fit GridSearchCV to the training data\n",
        "print(\"Starting GridSearchCV for hyperparameter tuning...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 6. Print the best parameters found by GridSearchCV\n",
        "print(\"\\nBest parameters found:\", grid_search.best_params_)\n",
        "\n",
        "# 7. Store the best model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "print(\"Best XGBoost model stored.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GridSearchCV for hyperparameter tuning...\n",
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "\n",
            "Best parameters found: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "Best XGBoost model stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1282bf65"
      },
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained and tuned XGBoost model's performance, focusing on the R² score to ensure it meets the expected accuracy of 0.90 – 0.97.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99d6852"
      },
      "source": [
        "**Reasoning**:\n",
        "I will make predictions on the test set using the best XGBoost model, calculate the R² score, print the score, and then check if it falls within the desired range of 0.90 to 0.97.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53557fc7",
        "outputId": "911c96df-632d-41c9-fecf-44a52a9e19ba"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1. Use the best_xgb_model to make predictions on the test dataset X_test\n",
        "y_pred = best_xgb_model.predict(X_test)\n",
        "\n",
        "# 2. Calculate the R² score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# 3. Print the calculated R² score\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n",
        "# 4. Add a conditional statement to check if the R² score is between 0.90 and 0.97\n",
        "if 0.90 <= r2 <= 0.97:\n",
        "    print(\"Model performance target met: R² score is within the range of 0.90 to 0.97.\")\n",
        "else:\n",
        "    print(\"Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: -0.0798\n",
            "Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4b3ee71"
      },
      "source": [
        "## Retrain and Tune XGBoost Model and Evaluate Performance (Attempt 2)\n",
        "\n",
        "### Subtask:\n",
        "Retrain and tune the XGBoost Regressor model with an expanded hyperparameter grid to improve performance, and then evaluate its R² score to ensure it meets the target range of 0.90 to 0.97.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c65ebc2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous R² score was negative, indicating a very poor model fit. To improve performance and reach the target R² range, I need to expand the hyperparameter grid for the XGBoost model to allow for more extensive tuning. This will help `GridSearchCV` explore a wider range of parameter combinations to find a better performing model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed1abaf",
        "outputId": "6f78fd1d-e98a-4f96-d3b5-f7d4d34ce8fc"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1. Define an expanded parameter grid for hyperparameter tuning\n",
        "param_grid_expanded = {\n",
        "    'n_estimators': [200, 400, 600],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [5, 7, 9],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "# 2. Instantiate an XGBRegressor model with a random state\n",
        "xgb_expanded = XGBRegressor(random_state=42)\n",
        "\n",
        "# 3. Initialize GridSearchCV with the expanded parameter grid\n",
        "grid_search_expanded = GridSearchCV(estimator=xgb_expanded, param_grid=param_grid_expanded,\n",
        "                                  scoring='r2', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# 4. Fit GridSearchCV to the training data\n",
        "print(\"Starting GridSearchCV with expanded hyperparameter grid...\")\n",
        "grid_search_expanded.fit(X_train, y_train)\n",
        "\n",
        "# 5. Print the best parameters found by GridSearchCV\n",
        "print(\"\\nBest parameters found with expanded grid:\", grid_search_expanded.best_params_)\n",
        "\n",
        "# 6. Store the best model\n",
        "best_xgb_model_expanded = grid_search_expanded.best_estimator_\n",
        "print(\"Best XGBoost model with expanded grid stored.\")\n",
        "\n",
        "# 7. Use the best_xgb_model_expanded to make predictions on the test dataset X_test\n",
        "y_pred_expanded = best_xgb_model_expanded.predict(X_test)\n",
        "\n",
        "# 8. Calculate the R² score\n",
        "r2_expanded = r2_score(y_test, y_pred_expanded)\n",
        "\n",
        "# 9. Print the calculated R² score\n",
        "print(f\"\\nExpanded R² Score: {r2_expanded:.4f}\")\n",
        "\n",
        "# 10. Add a conditional statement to check if the R² score is between 0.90 and 0.97\n",
        "if 0.90 <= r2_expanded <= 0.97:\n",
        "    print(\"Model performance target met: R² score is within the range of 0.90 to 0.97.\")\n",
        "else:\n",
        "    print(\"Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GridSearchCV with expanded hyperparameter grid...\n",
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "\n",
            "Best parameters found with expanded grid: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n",
            "Best XGBoost model with expanded grid stored.\n",
            "\n",
            "Expanded R² Score: -0.0823\n",
            "Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e88518a"
      },
      "source": [
        "**Reasoning**:\n",
        "Given the persistently negative R² score, I will apply StandardScaler to the numerical features of the training and testing datasets. While tree-based models are less sensitive to scaling, it can sometimes improve performance by normalizing the range of input variables, especially when the initial R² is very poor. After scaling, I will retrain and tune the XGBoost model using the same expanded hyperparameter grid.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "396570d5",
        "outputId": "e08de348-fcd0-406d-dab6-1388bc9d5797"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Identify numerical columns for scaling (excluding one-hot encoded 'Crop' columns)\n",
        "numerical_cols = ['Temperature (°C)', 'Rainfall (mm)', 'Soil pH', 'Nitrogen (N)', 'Phosphorus (P)', 'Potassium (K)']\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply StandardScaler to numerical columns in X_train and X_test\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train_scaled[numerical_cols])\n",
        "X_test_scaled[numerical_cols] = scaler.transform(X_test_scaled[numerical_cols])\n",
        "\n",
        "print(\"Numerical features scaled for X_train and X_test.\")\n",
        "\n",
        "# Define the expanded parameter grid (same as before)\n",
        "param_grid_expanded = {\n",
        "    'n_estimators': [200, 400, 600],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [5, 7, 9],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "# Instantiate an XGBRegressor model with a random state\n",
        "xgb_scaled = XGBRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV with the expanded parameter grid and scaled data\n",
        "grid_search_scaled = GridSearchCV(estimator=xgb_scaled, param_grid=param_grid_expanded,\n",
        "                                  scoring='r2', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the scaled training data\n",
        "print(\"\\nStarting GridSearchCV with scaled data and expanded hyperparameter grid...\")\n",
        "grid_search_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"\\nBest parameters found with scaled data:\", grid_search_scaled.best_params_)\n",
        "\n",
        "# Store the best model\n",
        "best_xgb_model_scaled = grid_search_scaled.best_estimator_\n",
        "print(\"Best XGBoost model with scaled data stored.\")\n",
        "\n",
        "# Use the best_xgb_model_scaled to make predictions on the scaled test dataset X_test_scaled\n",
        "y_pred_scaled = best_xgb_model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the R² score\n",
        "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the calculated R² score\n",
        "print(f\"\\nScaled R² Score: {r2_scaled:.4f}\")\n",
        "\n",
        "# Add a conditional statement to check if the R² score is between 0.90 and 0.97\n",
        "if 0.90 <= r2_scaled <= 0.97:\n",
        "    print(\"Model performance target met: R² score is within the range of 0.90 to 0.97.\")\n",
        "else:\n",
        "    print(\"Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical features scaled for X_train and X_test.\n",
            "\n",
            "Starting GridSearchCV with scaled data and expanded hyperparameter grid...\n",
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1437522759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Fit GridSearchCV to the scaled training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting GridSearchCV with scaled data and expanded hyperparameter grid...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mgrid_search_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Print the best parameters found by GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39057240"
      },
      "source": [
        "# Task\n",
        "Refine the XGBoost tuning strategy by implementing a more robust `GridSearchCV` on the scaled data, expanding the hyperparameter grid to include wider ranges for `learning_rate` and `n_estimators`, higher `max_depth` values, and regularization parameters (`min_child_weight`, `gamma`), aiming to achieve an R² score between 0.90 and 0.97."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ebd30f"
      },
      "source": [
        "## Refine XGBoost Tuning Strategy (Attempt 3)\n",
        "\n",
        "### Subtask:\n",
        "Refine the XGBoost Regressor model tuning strategy by implementing a more robust GridSearchCV on the scaled data. This involves expanding the hyperparameter grid to include wider ranges for 'learning_rate' and 'n_estimators', higher 'max_depth' values, and regularization parameters ('min_child_weight', 'gamma') to better control model complexity and improve the R² score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a871e975"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts at hyperparameter tuning did not yield satisfactory R² scores. To address this, I will implement a more robust GridSearchCV with an expanded hyperparameter grid, including regularization parameters, as specified in the instructions, to find a better performing XGBoost model on the scaled data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7a67d6",
        "outputId": "fa9108fe-00f1-4bcf-cd07-76e83ddf093d"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Define a new, expanded hyperparameter grid (param_grid_refined)\n",
        "param_grid_refined = {\n",
        "    'n_estimators': [300, 500, 700],\n",
        "    'learning_rate': [0.005, 0.01, 0.05, 0.1],\n",
        "    'max_depth': [6, 8, 10],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# 2. Instantiate an XGBRegressor model with random_state=42\n",
        "xgb_refined = XGBRegressor(random_state=42, tree_method='hist')\n",
        "\n",
        "# 3. Initialize GridSearchCV with the XGBRegressor instance, the param_grid_refined\n",
        "grid_search_refined = GridSearchCV(estimator=xgb_refined, param_grid=param_grid_refined,\n",
        "                                   scoring='r2', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# 4. Fit GridSearchCV to the scaled training data (X_train_scaled, y_train)\n",
        "print(\"\\nStarting GridSearchCV with refined hyperparameter grid on scaled data...\")\n",
        "grid_search_refined.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 5. Print the best parameters found by GridSearchCV\n",
        "print(\"\\nBest parameters found with refined grid:\", grid_search_refined.best_params_)\n",
        "\n",
        "# 6. Store the best estimator from GridSearchCV as best_xgb_model_refined\n",
        "best_xgb_model_refined = grid_search_refined.best_estimator_\n",
        "print(\"Best refined XGBoost model stored.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting GridSearchCV with refined hyperparameter grid on scaled data...\n",
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "\n",
            "Best parameters found with refined grid: {'gamma': 0.1, 'learning_rate': 0.005, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 300}\n",
            "Best refined XGBoost model stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b2053f2"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `GridSearchCV` with the refined hyperparameter grid has completed and the best model has been stored, I need to evaluate its performance by calculating the R² score on the scaled test set to determine if the target performance range of 0.90 to 0.97 has been met.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8f1615",
        "outputId": "96468fa7-42b0-45a5-9c0e-aedd0f0b388e"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 7. Use the best_xgb_model_refined to make predictions on the scaled test dataset X_test_scaled\n",
        "y_pred_refined = best_xgb_model_refined.predict(X_test_scaled)\n",
        "\n",
        "# 8. Calculate the R² score\n",
        "r2_refined = r2_score(y_test, y_pred_refined)\n",
        "\n",
        "# 9. Print the calculated R² score\n",
        "print(f\"\\nRefined R² Score: {r2_refined:.4f}\")\n",
        "\n",
        "# 10. Add a conditional statement to check if the R² score is between 0.90 and 0.97\n",
        "if 0.90 <= r2_refined <= 0.97:\n",
        "    print(\"Model performance target met: R² score is within the range of 0.90 to 0.97.\")\n",
        "else:\n",
        "    print(\"Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Refined R² Score: -0.0192\n",
            "Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0abf1bad"
      },
      "source": [
        "**Reasoning**:\n",
        "Despite expanding the hyperparameter grid and applying scaling, the R² score remains negative, indicating severe model performance issues. To make a final attempt within the 'tuning strategy' subtask, I will drastically expand the hyperparameter grid for XGBoost Regressor, including broader ranges for `n_estimators`, `learning_rate`, `max_depth`, and introducing more regularization parameters (`lambda`, `alpha`) to explore a much wider parameter space and potentially find a combination that yields a positive R² score closer to the target range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "1d36ba65",
        "outputId": "e186b2cd-4c77-422d-e9f5-573556a7789b"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1. Define a dramatically expanded hyperparameter grid (param_grid_ultimate)\n",
        "param_grid_ultimate = {\n",
        "    'n_estimators': [500, 1000, 1500, 2000],\n",
        "    'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
        "    'max_depth': [6, 8, 10, 12],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'reg_alpha': [0, 0.001, 0.005, 0.01],\n",
        "    'reg_lambda': [0.5, 1, 1.5]\n",
        "}\n",
        "\n",
        "# 2. Instantiate an XGBRegressor model with random_state=42\n",
        "xgb_ultimate = XGBRegressor(random_state=42, tree_method='hist')\n",
        "\n",
        "# 3. Initialize GridSearchCV with the XGBRegressor instance and the ultimate parameter grid\n",
        "grid_search_ultimate = GridSearchCV(estimator=xgb_ultimate, param_grid=param_grid_ultimate,\n",
        "                                    scoring='r2', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# 4. Fit GridSearchCV to the scaled training data (X_train_scaled, y_train)\n",
        "print(\"\\nStarting GridSearchCV with ultimate hyperparameter grid on scaled data...\")\n",
        "grid_search_ultimate.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 5. Print the best parameters found by GridSearchCV\n",
        "print(\"\\nBest parameters found with ultimate grid:\", grid_search_ultimate.best_params_)\n",
        "\n",
        "# 6. Store the best estimator from GridSearchCV as best_xgb_model_ultimate\n",
        "best_xgb_model_ultimate = grid_search_ultimate.best_estimator_\n",
        "print(\"Best ultimate XGBoost model stored.\")\n",
        "\n",
        "# 7. Use the best_xgb_model_ultimate to make predictions on the scaled test dataset X_test_scaled\n",
        "y_pred_ultimate = best_xgb_model_ultimate.predict(X_test_scaled)\n",
        "\n",
        "# 8. Calculate the R² score\n",
        "r2_ultimate = r2_score(y_test, y_pred_ultimate)\n",
        "\n",
        "# 9. Print the calculated R² score\n",
        "print(f\"\\nUltimate R² Score: {r2_ultimate:.4f}\")\n",
        "\n",
        "# 10. Add a conditional statement to check if the R² score is between 0.90 and 0.97\n",
        "if 0.90 <= r2_ultimate <= 0.97:\n",
        "    print(\"Model performance target met: R² score is within the range of 0.90 to 0.97.\")\n",
        "else:\n",
        "    print(\"Model performance target NOT met: R² score is outside the range of 0.90 to 0.97.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting GridSearchCV with ultimate hyperparameter grid on scaled data...\n",
            "Fitting 5 folds for each of 110592 candidates, totalling 552960 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2900899057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 4. Fit GridSearchCV to the scaled training data (X_train_scaled, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting GridSearchCV with ultimate hyperparameter grid on scaled data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgrid_search_ultimate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 5. Print the best parameters found by GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 1. Define your existing param_grid_ultimate (kept as is)\n",
        "param_grid_ultimate = {\n",
        "    'n_estimators': [500, 1000, 1500, 2000],\n",
        "    'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
        "    'max_depth': [6, 8, 10, 12],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    # ... include your other parameters here ...\n",
        "}\n",
        "\n",
        "# 4. Fit RandomizedSearchCV instead of GridSearchCV\n",
        "# n_iter=100 means it will pick 100 random combinations to test\n",
        "random_search_ultimate = RandomizedSearchCV(\n",
        "    estimator=XGBRegressor(random_state=42),\n",
        "    param_distributions=param_grid_ultimate,\n",
        "    n_iter=100,\n",
        "    scoring='r2',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nStarting RandomizedSearchCV on scaled data...\")\n",
        "random_search_ultimate.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 5. Print the best parameters\n",
        "print(\"\\nBest parameters found:\", random_search_ultimate.best_params_)\n",
        "\n",
        "# 6. Store the best estimator\n",
        "best_xgb_model_ultimate = random_search_ultimate.best_estimator_\n",
        "\n",
        "# 7. Use the best model to make predictions\n",
        "y_pred_ultimate = best_xgb_model_ultimate.predict(X_test_scaled)\n",
        "\n",
        "# 8. Calculate the R² score\n",
        "r2_ultimate = r2_score(y_test, y_pred_ultimate)\n",
        "\n",
        "# 9. & 10. Print and Check Target (Same as your previous logic)\n",
        "print(f\"\\nUltimate R² Score: {r2_ultimate:.4f}\")\n",
        "\n",
        "if 0.90 <= r2_ultimate <= 0.97:\n",
        "    print(\"Model performance target met: R² score is within the range of 0.90 to 0.97.\")\n",
        "else:\n",
        "    print(\"Model performance target NOT met.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1SGDy4LHwQn",
        "outputId": "6ded6ab2-0b8d-497c-c5e0-e136341771d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RandomizedSearchCV on scaled data...\n",
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "\n",
            "Best parameters found: {'n_estimators': 500, 'min_child_weight': 7, 'max_depth': 6, 'learning_rate': 0.001}\n",
            "\n",
            "Ultimate R² Score: 0.0404\n",
            "Model performance target NOT met.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d20c5ad2"
      },
      "source": [
        "# Task\n",
        "## Visualize Feature Importance\n",
        "\n",
        "### Subtask:\n",
        "Extract the feature importance from the `best_xgb_model_ultimate` and create a visualization (e.g., a bar chart) to display the most influential features on crop yield, using `X_train_scaled` to get the feature names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bae2e69c"
      },
      "source": [
        "## Visualize Feature Importance\n",
        "\n",
        "### Subtask:\n",
        "Extract the feature importance from the `best_xgb_model_ultimate` and create a visualization (e.g., a bar chart) to display the most influential features on crop yield, using `X_train_scaled` to get the feature names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d3d0447"
      },
      "source": [
        "**Reasoning**:\n",
        "I will extract the feature importances from the `best_xgb_model_ultimate`, create a Pandas Series with feature names, sort them, and then plot a bar chart to visualize the most influential features as requested in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "74891e86",
        "outputId": "2e57824f-f8c7-4528-8902-f36c11f1550f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Extract feature importances\n",
        "feature_importances = best_xgb_model_ultimate.feature_importances_\n",
        "\n",
        "# 2. Create a Pandas Series mapping importances to feature names\n",
        "feature_names = X_train_scaled.columns\n",
        "importance_series = pd.Series(feature_importances, index=feature_names)\n",
        "\n",
        "# 3. Sort the feature importances in descending order\n",
        "sorted_importance_series = importance_series.sort_values(ascending=False)\n",
        "\n",
        "# 4. Create a bar plot of the sorted feature importances\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=sorted_importance_series.values, y=sorted_importance_series.index)\n",
        "plt.title('XGBoost Feature Importance for Crop Yield Prediction')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature Name')\n",
        "plt.tight_layout()\n",
        "\n",
        "# 5. Display the plot\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8babb140"
      },
      "source": [
        "## Summary of Findings: Feature Importance\n",
        "\n",
        "The feature importance analysis for the XGBoost model provides valuable insights into the factors influencing crop yield:\n",
        "\n",
        "*   **N-P-K Components**: Nitrogen (N) stands out as a highly influential factor, ranking among the top features in predicting crop yield. Phosphorus (P) and Potassium (K) also contribute, though to a lesser extent than Nitrogen.\n",
        "\n",
        "*   **Climate Factors**: Temperature (°C) is a significant predictor, indicating that optimal temperature ranges are crucial for crop growth. Rainfall (mm) also plays a notable role, highlighting its importance for yield.\n",
        "\n",
        "*   **Soil pH**: Soil pH is another critical environmental factor, demonstrating a strong influence on crop yield, on par with or exceeding some N-P-K and climate components.\n",
        "\n",
        "*   **Crop Type**: The type of crop itself (represented by the one-hot encoded 'Crop' features) is also very important, suggesting that yield predictions are highly dependent on the specific crop being cultivated.\n",
        "\n",
        "In conclusion, Nitrogen, Soil pH, and Temperature are the most dominant factors, followed by specific crop types and Rainfall, while Phosphorus and Potassium show moderate importance in predicting crop yield according to this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e82ffeed"
      },
      "source": [
        "## Summary of Findings: Feature Importance\n",
        "\n",
        "The feature importance analysis for the XGBoost model provides valuable insights into the factors influencing crop yield:\n",
        "\n",
        "*   **N-P-K Components**: Nitrogen (N) stands out as a highly influential factor, ranking among the top features in predicting crop yield. Phosphorus (P) and Potassium (K) also contribute, though to a lesser extent than Nitrogen.\n",
        "\n",
        "*   **Climate Factors**: Temperature (°C) is a significant predictor, indicating that optimal temperature ranges are crucial for crop growth. Rainfall (mm) also plays a notable role, highlighting its importance for yield.\n",
        "\n",
        "*   **Soil pH**: Soil pH is another critical environmental factor, demonstrating a strong influence on crop yield, on par with or exceeding some N-P-K and climate components.\n",
        "\n",
        "*   **Crop Type**: The type of crop itself (represented by the one-hot encoded 'Crop' features) is also very important, suggesting that yield predictions are highly dependent on the specific crop being cultivated.\n",
        "\n",
        "In conclusion, Nitrogen, Soil pH, and Temperature are the most dominant factors, followed by specific crop types and Rainfall, while Phosphorus and Potassium show moderate importance in predicting crop yield according to this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39a2f9fe"
      },
      "source": [
        "## Summarize Findings\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the research, including data analysis, preprocessing, XGBoost tuning attempts, the final R² score, and an analysis of feature importance. Discuss why the model struggled to meet the target R² range and the suitability and limitations of XGBoost for this dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da7d12f9"
      },
      "source": [
        "## Summarize Findings\n",
        "\n",
        "### Data Analysis Overview\n",
        "\n",
        "The dataset `crop_yield_fertilizer_300.csv` consists of 300 entries and 9 columns, with no missing values, as indicated by `df.info()`. The columns include an `ID`, `Crop` type (categorical), and several numerical features: `Temperature (°C)`, `Rainfall (mm)`, `Soil pH`, `Nitrogen (N)`, `Phosphorus (P)`, `Potassium (K)`, and the target variable `Yield (tons/ha)`.\n",
        "\n",
        "**Descriptive Statistics from `df.describe()`: **\n",
        "*   **Temperature (°C)**: Ranges from 15.1°C to 35.0°C, with an average of 24.71°C.\n",
        "*   **Rainfall (mm)**: Ranges from 407mm to 1998mm, with an average of 1179.64mm.\n",
        "*   **Soil pH**: Ranges from 5.5 to 7.5, averaging around 6.45.\n",
        "*   **Nitrogen (N)**: Ranges from 30 to 80, averaging 53.86.\n",
        "*   **Phosphorus (P)**: Ranges from 20 to 70, averaging 45.44.\n",
        "*   **Potassium (K)**: Ranges from 15 to 60, averaging 38.61.\n",
        "*   **Yield (tons/ha)**: The target variable, ranging from 1.52 tons/ha to 7.00 tons/ha, with an average of 4.11 tons/ha.\n",
        "\n",
        "The dataset provides a balanced mix of environmental factors and nutrient levels, along with crop type, to predict yield. The numerical features show a reasonable spread without extreme outliers evident in the `describe()` output, suggesting general consistency. The `Crop` column is the only categorical feature identified for special handling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "566cc0cd"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Data preprocessing involved several key steps to prepare the dataset for model training:\n",
        "\n",
        "1.  **Feature and Target Separation**: The target variable, `'Yield (tons/ha)'`, was separated into `y`, while the remaining columns formed the feature set `X`. The `'ID'` column was dropped from `X` as it provides no predictive power.\n",
        "\n",
        "2.  **Categorical Feature Encoding**: The `Crop` column, being a categorical feature, was transformed using one-hot encoding via `pd.get_dummies()`. This created new binary columns for each crop type, making them suitable for the XGBoost model. `drop_first=True` was used to avoid multicollinearity.\n",
        "\n",
        "3.  **Train-Test Split**: The preprocessed data (`X` and `y`) was then split into training and testing sets using `train_test_split` from `sklearn.model_selection`. A `test_size` of 0.2 (20% of the data) was allocated for testing, and `random_state=42` was set for reproducibility. This resulted in:\n",
        "    *   `X_train` and `y_train` for model training (240 samples).\n",
        "    *   `X_test` and `y_test` for model evaluation (60 samples).\n",
        "\n",
        "4.  **Feature Scaling**: To potentially improve model performance, especially after repeated negative R² scores, `StandardScaler` was applied to the numerical features (`Temperature (°C)`, `Rainfall (mm)`, `Soil pH`, `Nitrogen (N)`, `Phosphorus (P)`, `Potassium (K)`) of both the training and testing sets. This normalized the features to have zero mean and unit variance, creating `X_train_scaled` and `X_test_scaled`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c2647d2"
      },
      "source": [
        "### XGBoost Model Training and Tuning Attempts\n",
        "\n",
        "The XGBoost Regressor model was trained and tuned through several iterations, progressively expanding the hyperparameter search space in an attempt to achieve the target R² score of 0.90 to 0.97. Initially, the model showed very poor performance, indicated by negative R² scores.\n",
        "\n",
        "1.  **Initial Tuning Attempt (GridSearchCV - param_grid)**:\n",
        "    *   **Hyperparameters**: `n_estimators`: [100, 200, 300], `learning_rate`: [0.01, 0.05, 0.1], `max_depth`: [3, 5, 7].\n",
        "    *   **Best Parameters**: `{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}`.\n",
        "    *   **Resulting R² Score**: `-0.0798`. This negative score indicated that the model performed worse than simply predicting the mean of the target variable, suggesting either inappropriate hyperparameters or fundamental issues with the data or model setup.\n",
        "\n",
        "2.  **Second Tuning Attempt (GridSearchCV - param_grid_expanded)**:\n",
        "    *   **Reasoning**: To address the negative R² score, the hyperparameter grid was significantly expanded to explore a wider range of values for existing parameters and introduce new ones like `subsample` and `colsample_bytree`.\n",
        "    *   **Hyperparameters**: `n_estimators`: [200, 400, 600], `learning_rate`: [0.01, 0.05, 0.1, 0.2], `max_depth`: [5, 7, 9], `subsample`: [0.7, 0.8, 0.9], `colsample_bytree`: [0.7, 0.8, 0.9].\n",
        "    *   **Best Parameters**: `{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}`.\n",
        "    *   **Resulting R² Score**: `-0.0823`. The score remained negative, indicating that simply expanding the grid without other changes was not sufficient.\n",
        "\n",
        "3.  **Third Tuning Attempt (GridSearchCV with Scaled Data - param_grid_refined)**:\n",
        "    *   **Reasoning**: Given the persistent negative R² scores, feature scaling was introduced using `StandardScaler` on numerical features. The hyperparameter grid was also refined to include regularization parameters `min_child_weight` and `gamma`.\n",
        "    *   **Hyperparameters**: `n_estimators`: [300, 500, 700], `learning_rate`: [0.005, 0.01, 0.05, 0.1], `max_depth`: [6, 8, 10], `min_child_weight`: [1, 3, 5], `gamma`: [0, 0.1, 0.2].\n",
        "    *   **Best Parameters**: `{'gamma': 0.1, 'learning_rate': 0.005, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 300}`.\n",
        "    *   **Resulting R² Score**: `-0.0192`. While slightly improved (less negative), the score was still far from the target, suggesting that scaling alone or the refined grid was not enough.\n",
        "\n",
        "4.  **Fourth Tuning Attempt (RandomizedSearchCV with Scaled Data - param_grid_ultimate)**:\n",
        "    *   **Reasoning**: A dramatically expanded hyperparameter grid was defined, including wider ranges and additional regularization parameters (`reg_alpha`, `reg_lambda`). Due to the size of this grid (over 110,000 combinations), `RandomizedSearchCV` was used with `n_iter=100` to efficiently sample a diverse set of parameter combinations. The `tree_method='hist'` was also specified for potentially faster training.\n",
        "    *   **Hyperparameters**: `n_estimators`: [500, 1000, 1500, 2000], `learning_rate`: [0.001, 0.005, 0.01, 0.05], `max_depth`: [6, 8, 10, 12], `min_child_weight`: [1, 3, 5, 7], `gamma`: [0, 0.1, 0.2, 0.3], `subsample`: [0.7, 0.8, 0.9], `colsample_bytree`: [0.7, 0.8, 0.9], `reg_alpha`: [0, 0.001, 0.005, 0.01], `reg_lambda`: [0.5, 1, 1.5].\n",
        "    *   **Best Parameters**: `{'n_estimators': 500, 'min_child_weight': 7, 'max_depth': 6, 'learning_rate': 0.001}` (Note: The executed code for this step only included `n_estimators`, `learning_rate`, `max_depth`, and `min_child_weight` in `param_grid_ultimate`, not all the listed parameters, which explains the best parameters found).\n",
        "    *   **Resulting R² Score**: `0.0404`. This was the first positive R² score achieved, indicating a slight improvement over a baseline model, but still significantly below the target range of 0.90 to 0.97.\n",
        "\n",
        "Throughout these attempts, despite extensive hyperparameter tuning and data scaling, the XGBoost model consistently struggled to achieve a high R² score, falling short of the target performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74db981c"
      },
      "source": [
        "### Final R² Score and Model Performance Discussion\n",
        "\n",
        "Despite multiple attempts at hyperparameter tuning, including expansive grids and the use of `StandardScaler` on numerical features, the `best_xgb_model_ultimate` achieved a final R² score of **0.0404**.\n",
        "\n",
        "This score is significantly below the target range of 0.90 to 0.97 and indicates that the model explains only a very small percentage (approximately 4%) of the variance in crop yield. In practical terms, it means the model is performing only slightly better than a naive model that would simply predict the mean crop yield for all cases.\n",
        "\n",
        "Several factors could contribute to the model's struggle to meet the target R² range:\n",
        "\n",
        "1.  **Limited Data Complexity**: The dataset contains only 300 entries, which is a relatively small sample size for training complex models like XGBoost, especially when aiming for high accuracy. With limited data, it's harder for the model to learn robust patterns and generalize well to unseen data.\n",
        "2.  **Lack of Predictive Power in Features**: It's possible that the features available in the dataset (`Temperature`, `Rainfall`, `Soil pH`, `N-P-K levels`, `Crop` type) do not sufficiently capture the underlying mechanisms that drive crop yield variation. Crop yield can be influenced by many other unmeasured factors, such as specific crop varieties, pest infestations, disease outbreaks, irrigation practices, sunlight hours, soil type composition (beyond pH), and agricultural management techniques, which are not present in this dataset.\n",
        "3.  **High Intrinsic Noise/Variability**: Crop yield is inherently complex and can be highly variable due to numerous stochastic environmental and biological factors. If the inherent noise or unexplainable variance in the target variable is high, even a perfect model might struggle to achieve a very high R² score.\n",
        "4.  **Model Hyperparameters**: While extensive tuning was performed, it's always possible that the optimal combination of hyperparameters was still not found, or that the chosen search space, even if broad, didn't perfectly align with the model's needs for this specific dataset. However, given the consistently low scores across diverse tuning attempts, it points more towards data limitations.\n",
        "5.  **Linearity Assumption vs. Reality**: Although XGBoost is a powerful non-linear model, if the true relationship between the features and crop yield is extremely complex or chaotic, even advanced models might struggle with a limited feature set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51b67a7d"
      },
      "source": [
        "### Analysis of Feature Importance\n",
        "\n",
        "The feature importance visualization (generated from `best_xgb_model_ultimate`) provides insights into which factors the model considered most influential in predicting crop yield. The features are ranked as follows (most influential first):\n",
        "\n",
        "1.  **Nitrogen (N)**: With the highest importance score, Nitrogen stands out as the most crucial nutrient for crop yield in this dataset, indicating its significant role in plant growth and productivity.\n",
        "2.  **Crop_Millet**: The presence of Millet as a crop type is also highly influential, suggesting that specific crop types have distinct yield characteristics.\n",
        "3.  **Soil pH**: Soil pH is another highly important factor, underscoring its fundamental role in nutrient availability and overall soil health for crop cultivation.\n",
        "4.  **Temperature (°C)**: Temperature is identified as a critical climate factor, directly impacting plant metabolic rates and growth cycles.\n",
        "5.  **Crop_Rice**: Similar to Millet, Rice as a crop type shows significant importance, highlighting the varying yield potential across different crops.\n",
        "6.  **Crop_Cotton**: Cotton also registers as an important crop-specific feature.\n",
        "7.  **Crop_Sugarcane**: Sugarcane, another crop type, demonstrates notable influence.\n",
        "8.  **Rainfall (mm)**: Rainfall is an important climate factor, essential for crop hydration and growth.\n",
        "9.  **Crop_Maize**: Maize shows a moderate level of importance.\n",
        "10. **Phosphorus (P)**: Phosphorus is less influential than Nitrogen but still contributes to the prediction, indicating its secondary importance among NPK components.\n",
        "11. **Potassium (K)**: Potassium, while important for plant health, appears to have the least direct impact on yield prediction among the NPK nutrients in this model.\n",
        "12. **Crop_Soybean**: Soybean shows relatively low importance.\n",
        "13. **Crop_Wheat**: Interestingly, `Crop_Wheat` registered a feature importance of `0.0000`, suggesting that for the `best_xgb_model_ultimate` and the given dataset, the presence of Wheat as a crop type did not contribute to the model's predictions.\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   **N–P–K Components**: Nitrogen (N) is by far the most influential among the N–P–K nutrients. Phosphorus (P) and Potassium (K) show considerably lower importance, with K being the least impactful. This suggests that while all are essential, Nitrogen levels have the strongest correlation with yield in this dataset.\n",
        "*   **Climate Factors**: Temperature (°C) and Rainfall (mm) are both important climate factors, with Temperature having a slightly higher influence than Rainfall. This aligns with general agricultural understanding that both ambient temperature and water availability are crucial for crop growth.\n",
        "*   **Soil pH**: Soil pH is a significant environmental factor, reflecting its critical role in nutrient uptake and plant health.\n",
        "*   **Crop Type**: The type of crop (`Crop_Millet`, `Crop_Rice`, `Crop_Cotton`, `Crop_Sugarcane`, `Crop_Maize`) also plays a substantial role, with some crop types being more influential than others, indicating inherent differences in yield potentials or responses to other features based on crop variety. The lack of importance for `Crop_Wheat` might suggest its yield is more stable or less dependent on the given environmental/nutrient factors compared to others, or that there's simply not enough variation in its data for the model to find patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34e332f6"
      },
      "source": [
        "### Suitability and Limitations of XGBoost for This Dataset\n",
        "\n",
        "XGBoost is a powerful and flexible gradient boosting framework widely used for tabular data, known for its ability to handle complex non-linear relationships and its robust performance. However, for this specific dataset, its suitability and limitations are evident from the results:\n",
        "\n",
        "**Suitability:**\n",
        "\n",
        "*   **Handles Mixed Data Types**: XGBoost inherently works well with both numerical and categorical features (after one-hot encoding), which was a strength given the `Crop` categorical variable.\n",
        "*   **Feature Importance Insights**: Despite the low R² score, XGBoost successfully provided valuable insights into feature importance, clearly indicating the most influential factors like Nitrogen, Soil pH, Temperature, and specific crop types. This interpretability is crucial for understanding the underlying agricultural dynamics.\n",
        "*   **Robustness to Scaling**: Tree-based models like XGBoost are generally less sensitive to feature scaling, though scaling was attempted to rule out any potential minor benefits. The model's inherent ability to find splits regardless of feature scale is a theoretical advantage.\n",
        "\n",
        "**Limitations Observed:**\n",
        "\n",
        "*   **Data Scarcity**: The most significant limitation was the small dataset size (300 samples). XGBoost, while robust, generally performs better with larger datasets where it can learn more generalizable patterns. With limited data, it is prone to capturing noise rather than true underlying relationships, or simply not finding strong enough patterns to model the target variable accurately.\n",
        "*   **Feature Information Content**: The persistently low R² scores across extensive tuning suggest that the available features, even if theoretically important, might not contain enough predictive information for this specific target variable. As discussed, many other unmeasured factors likely influence crop yield, which are not captured by the current dataset.\n",
        "*   **Overfitting Potential (despite regularization)**: Although XGBoost includes regularization parameters (`gamma`, `min_child_weight`, `subsample`, `colsample_bytree`, `reg_alpha`, `reg_lambda`), the small dataset size makes it challenging to prevent overfitting entirely, or conversely, the model might be too regularized, losing signal in an attempt to generalize from too little data.\n",
        "*   **Computational Cost of Extensive Tuning**: While powerful, the comprehensive `GridSearchCV` and `RandomizedSearchCV` approaches on expanded grids become computationally expensive, and even with significant resources, they might not yield the desired performance if the fundamental data limitations persist.\n",
        "\n",
        "In conclusion, while XGBoost is a suitable choice for regression tasks and provides excellent insights into feature importance, its performance on this dataset was severely hampered by the limited sample size and potentially the lack of sufficiently rich or comprehensive features to explain the variance in crop yield. Future improvements would likely require a much larger and more diverse dataset incorporating a broader range of influencing factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97172134"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Present the final results, including the model's performance metrics, the feature importance visualization, and the comprehensive summary, concluding the crop yield prediction task as per the original objective, with a clear explanation of the outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8f9a200"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The objective was to present the final results of the crop yield prediction task, including model performance metrics, feature importance visualization, and a comprehensive summary.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The final XGBoost model achieved an R² score of 0.0404, which is significantly below the target range of 0.90 to 0.97, indicating the model explains only about 4% of the variance in crop yield.\n",
        "*   Despite extensive hyperparameter tuning using GridSearchCV and RandomizedSearchCV, the model consistently struggled, with initial R² scores being negative before reaching a slightly positive but very low value.\n",
        "*   The feature importance analysis revealed that Nitrogen (N) was the most influential factor, followed by Crop Type (specifically Millet, Rice, Cotton, and Sugarcane), Soil pH, and Temperature ($\\circ$C).\n",
        "*   Rainfall (mm) was also identified as an important climate factor, while Phosphorus (P) and Potassium (K) had less influence compared to Nitrogen.\n",
        "*   The `Crop_Wheat` feature registered negligible importance in the final model.\n",
        "*   The dataset contained 300 entries with 9 columns, including categorical 'Crop' type and several numerical features related to environmental factors and nutrient levels.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The primary limitation of the model's performance was the small dataset size (300 samples), which hindered the model's ability to learn robust and generalizable patterns.\n",
        "*   To significantly improve crop yield prediction, future efforts should focus on acquiring a much larger and more diverse dataset that incorporates additional factors beyond the current features (e.g., specific crop varieties, pest infestations, disease, irrigation, sunlight hours, detailed soil composition, and agricultural management practices).\n"
      ]
    }
  ]
}